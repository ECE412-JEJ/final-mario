[NeMo W 2022-12-01 23:24:33 optimizers:47] Apex was not found. Using the lamb optimizer will error out.
[NeMo W 2022-12-01 23:24:35 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_text_dali.AudioToCharDALIDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2022-12-01 23:24:35 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()
      deprecation_warning(message=message)
    
[NeMo W 2022-12-01 23:24:35 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/hydra/experimental/initialize.py:45: UserWarning: 
    The version_base parameter is not specified.
    Please specify a compatability version level, or None.
    Will assume defaults for version 1.1
      self.delegate = real_initialize(
    
[NeMo W 2022-12-01 23:24:35 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()
      deprecation_warning(message=message)
    
[NeMo W 2022-12-01 23:24:37 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.
      rank_zero_deprecation(
    
[NeMo W 2022-12-01 23:24:37 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.
      rank_zero_deprecation(
    
[NeMo W 2022-12-01 23:24:38 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:59: LightningDeprecationWarning: Setting `Trainer(flush_logs_every_n_steps=1000)` is deprecated in v1.5 and will be removed in v1.7. Please configure flushing in the logger instead.
      rank_zero_deprecation(
    
[NeMo W 2022-12-01 23:24:38 modelPT:138] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    dataset:
      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithDursF0Dataset
      manifest_filepath: /afs/ee.cooper.edu/user/j/jiyoon.pyo/final-mario/content/trainfiles.json
      max_duration: null
      min_duration: 0.1
      int_values: false
      load_audio: false
      normalize: false
      sample_rate: 22050
      trim: false
      durs_file: /afs/ee.cooper.edu/user/j/jiyoon.pyo/final-mario/voice_sample/mario/durations.pt
      f0_file: /afs/ee.cooper.edu/user/j/jiyoon.pyo/final-mario/voice_sample/mario/f0s.pt
      blanking: true
      vocab:
        notation: phonemes
        punct: true
        spaces: true
        stresses: false
        add_blank_at: last
    dataloader_params:
      drop_last: false
      shuffle: true
      batch_size: 64
      num_workers: 4
    
[NeMo W 2022-12-01 23:24:38 modelPT:145] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    dataset:
      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithDursF0Dataset
      manifest_filepath: /afs/ee.cooper.edu/user/j/jiyoon.pyo/final-mario/content/valfiles.json
      max_duration: null
      min_duration: 0.1
      int_values: false
      load_audio: false
      normalize: false
      sample_rate: 22050
      trim: false
      durs_file: /afs/ee.cooper.edu/user/j/jiyoon.pyo/final-mario/voice_sample/mario/durations.pt
      f0_file: /afs/ee.cooper.edu/user/j/jiyoon.pyo/final-mario/voice_sample/mario/f0s.pt
      blanking: true
      vocab:
        notation: phonemes
        punct: true
        spaces: true
        stresses: false
        add_blank_at: last
    dataloader_params:
      drop_last: false
      shuffle: false
      batch_size: 64
      num_workers: 1
    
[NeMo W 2022-12-01 23:24:39 exp_manager:705] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 5 epochs to ensure that checkpointing will not error out.
[NeMo W 2022-12-01 23:24:41 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
      rank_zero_warn(
    
[NeMo W 2022-12-01 23:24:42 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
      warning_cache.warn(
    
[NeMo W 2022-12-01 23:24:42 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (5) is smaller than the logging interval Trainer(log_every_n_steps=200). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
      rank_zero_warn(
    
[NeMo W 2022-12-01 23:24:43 nemo_logging:349] /afs/ee.cooper.edu/user/j/jiyoon.pyo/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/closure.py:35: LightningDeprecationWarning: One of the returned values {'progress_bar'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`
      rank_zero_deprecation(
    
